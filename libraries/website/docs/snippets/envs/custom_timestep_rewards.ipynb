{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704427a9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This file is generated from a Mathy (https://mathy.ai) code example.\n",
    "!pip install mathy --upgrade\n",
    "\"\"\"Environment with user-defined rewards per-timestep based on the\n",
    "rule that was applied by the agent.\"\"\"\n",
    "\n",
    "from typing import List, Type\n",
    "\n",
    "from mathy_core import BaseRule, rules\n",
    "from mathy_envs import MathyEnv, MathyEnvState\n",
    "\n",
    "\n",
    "class CustomTimestepRewards(MathyEnv):\n",
    "    def get_rewarding_actions(self, state: MathyEnvState) -> List[Type[BaseRule]]:\n",
    "        return [rules.AssociativeSwapRule]\n",
    "\n",
    "    def get_penalizing_actions(self, state: MathyEnvState) -> List[Type[BaseRule]]:\n",
    "        return [rules.CommutativeSwapRule]\n",
    "\n",
    "\n",
    "env = CustomTimestepRewards()\n",
    "problem = \"4x + y + 2x\"\n",
    "expression = env.parser.parse(problem)\n",
    "state = MathyEnvState(problem=problem)\n",
    "\n",
    "action = env.random_action(expression, rules.AssociativeSwapRule)\n",
    "_, transition, _ = env.get_next_state(state, action,)\n",
    "# Expect positive reward\n",
    "assert transition.reward > 0.0\n",
    "\n",
    "_, transition, _ = env.get_next_state(\n",
    "    state, env.random_action(expression, rules.CommutativeSwapRule),\n",
    ")\n",
    "# Expect neagative reward\n",
    "assert transition.reward < 0.0"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
